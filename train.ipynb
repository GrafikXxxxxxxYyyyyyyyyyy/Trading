{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e08ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import TradingDataset\n",
    "\n",
    "dataset = TradingDataset('data/', mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa6e161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "TradingTransformer(\n",
      "  (input_projection): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (pos_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x EncoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): GELU(approximate='none')\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x DecoderLayer(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (cross_attn): MultiHeadAttention(\n",
      "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (feed_forward): PositionwiseFeedForward(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (activation): GELU(approximate='none')\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_projection): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "{'model_type': 'TradingTransformer', 'feature_size': 256, 'd_model': 512, 'num_heads': 8, 'num_encoder_layers': 6, 'num_decoder_layers': 6, 'ff_hidden_dim': 2048, 'target_len': 32, 'dropout': 0.1, 'use_positional_encoding': True}\n"
     ]
    }
   ],
   "source": [
    "from models.model_wrapper import TradingModel\n",
    "\n",
    "\n",
    "# wrapper = TradingModel.from_config('src/ffn/ffn.json', device='mps') # DONE!\n",
    "# wrapper = TradingModel.from_config('src/lstm/lstm.json', device='mps') # DONE!\n",
    "wrapper = TradingModel.from_config('src/tcn/tcn.json', device='mps') # DONE!\n",
    "\n",
    "# wrapper = TradingModel.from_config('src/tft/tft.json', device='mps') # Типа тоже дан!\n",
    "# wrapper = TradingModel.from_config('src/cnn/cnn.json', device='mps') \n",
    "\n",
    "\n",
    "\n",
    "# wrapper = TradingModel.from_config('src/transformer/transformer.json', device='mps') \n",
    "# wrapper = TradingModel.from_config('', device='mps') \n",
    "\n",
    "print(wrapper.device)\n",
    "print(wrapper.model)\n",
    "print(wrapper.model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.train_pipeline import TradingTrainingArgs, TradingTrainer\n",
    "\n",
    "args = TradingTrainingArgs(\n",
    "    train_batch_size=16,\n",
    "    output_dir='pretrained-models',\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=1000,\n",
    "    tensorboard_log_dir='runs/trading_experiment',\n",
    ")\n",
    "\n",
    "trainer = TradingTrainer(\n",
    "    train_dataset=dataset,\n",
    "    model=wrapper,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74ac56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Инициализирован TensorBoard логгер. Логи будут сохранены в runs/trading_experiment/run_1756920958_TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:   3%|▎         | 1000/31664 [21:06<8:50:06,  1.04s/it, loss=0.331958]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель TradingTransformer успешно сохранена в pretrained-models/TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:   6%|▋         | 2000/31664 [38:16<8:29:54,  1.03s/it, loss=0.472920] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель TradingTransformer успешно сохранена в pretrained-models/TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:   9%|▉         | 3000/31664 [56:04<8:28:01,  1.06s/it, loss=0.468212] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель TradingTransformer успешно сохранена в pretrained-models/TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:  13%|█▎        | 4000/31664 [1:15:23<8:28:11,  1.10s/it, loss=0.390864] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель TradingTransformer успешно сохранена в pretrained-models/TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:  16%|█▌        | 5000/31664 [1:33:58<7:29:50,  1.01s/it, loss=0.342453] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель TradingTransformer успешно сохранена в pretrained-models/TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:  19%|█▉        | 6000/31664 [1:51:36<9:39:56,  1.36s/it, loss=0.264455] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель TradingTransformer успешно сохранена в pretrained-models/TradingTransformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "batch loss:  19%|█▉        | 6030/31664 [1:52:37<14:41:56,  2.06s/it, loss=0.256917]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Trading/pipelines/train_pipeline.py:126\u001b[39m, in \u001b[36mTradingTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m loss = loss_function(model_pred.float(), target.float())\n\u001b[32m    125\u001b[39m loss.backward()\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m optimizer.zero_grad()\n\u001b[32m    129\u001b[39m global_step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Trading/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:501\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28mself\u001b[39m = cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    500\u001b[39m profile_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Trading/.venv/lib/python3.11/site-packages/torch/autograd/profiler.py:776\u001b[39m, in \u001b[36mrecord_function.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m     \u001b[38;5;28mself\u001b[39m.record = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/Trading/.venv/lib/python3.11/site-packages/torch/_ops.py:1243\u001b[39m, in \u001b[36mOpOverloadPacket.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(\u001b[38;5;28mself\u001b[39m, *args, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1243\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67980a13",
   "metadata": {},
   "source": [
    "### Продолженное обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a4167f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapper = TradingModel.from_config('src/ffn/ffn.json', device='mps') # DONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cc810",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TradingTrainingArgs(\n",
    "    train_batch_size=16,\n",
    "    output_dir='pretrained-models',\n",
    "    learning_rate=1e-4,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=1000,\n",
    "    tensorboard_log_dir='runs/trading_experiment',\n",
    ")\n",
    "\n",
    "trainer = TradingTrainer(\n",
    "    train_dataset=dataset,\n",
    "    model=wrapper,\n",
    "    args=args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e808fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91543c6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
