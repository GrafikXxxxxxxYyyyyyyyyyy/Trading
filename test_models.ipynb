{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86535f79",
   "metadata": {},
   "source": [
    "### LSTM with Bahdanau attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "275bd2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход при обучении (с учителем): torch.Size([4, 32, 1])\n",
      "Выход при инференсе: torch.Size([4, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class BahdanauAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Механизм внимания Бахданау (Additive Attention).\n",
    "    Позволяет декодеру фокусироваться на разных частях выхода энкодера.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_hidden_dim, decoder_hidden_dim, attention_dim):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_hidden_dim (int): Размер скрытого состояния энкодера (H_enc).\n",
    "            decoder_hidden_dim (int): Размер скрытого состояния декодера (H_dec).\n",
    "            attention_dim (int): Размер внутреннего представления внимания.\n",
    "        \"\"\"\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.encoder_hidden_dim = encoder_hidden_dim\n",
    "        self.decoder_hidden_dim = decoder_hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "\n",
    "        # Линейные слои для преобразования входов перед вычислением внимания\n",
    "        self.W_enc = nn.Linear(encoder_hidden_dim, attention_dim, bias=False)\n",
    "        self.W_dec = nn.Linear(decoder_hidden_dim, attention_dim, bias=False)\n",
    "        self.V = nn.Linear(attention_dim, 1, bias=False)\n",
    "\n",
    "        # Инициализация весов для лучшей сходимости\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов для лучшей сходимости.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_hidden):\n",
    "        \"\"\"\n",
    "        Вычисляет веса внимания и контекстный вектор.\n",
    "        \n",
    "        Args:\n",
    "            encoder_outputs (torch.Tensor): Выходы энкодера [B, T_hist, H_enc].\n",
    "            decoder_hidden (torch.Tensor): Скрытое состояние декодера [B, H_dec].\n",
    "            \n",
    "        Returns:\n",
    "            context_vector (torch.Tensor): Контекстный вектор [B, H_enc].\n",
    "            attention_weights (torch.Tensor): Веса внимания [B, T_hist].\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = encoder_outputs.size()\n",
    "        \n",
    "        # decoder_hidden: [B, H_dec] -> [B, 1, H_dec] для broadcast\n",
    "        decoder_hidden_expanded = decoder_hidden.unsqueeze(1)\n",
    "        \n",
    "        # Вычисляем оценку внимания e_tj\n",
    "        energy = torch.tanh(\n",
    "            self.W_enc(encoder_outputs) + self.W_dec(decoder_hidden_expanded)\n",
    "        )\n",
    "        attention_scores = self.V(energy).squeeze(2) # [B, T_hist]\n",
    "\n",
    "        # Применяем softmax для получения весов внимания\n",
    "        attention_weights = F.softmax(attention_scores, dim=1) # [B, T_hist]\n",
    "\n",
    "        # Вычисляем контекстный вектор как взвешенную сумму выходов энкодера\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Энкодер для обработки исторических данных.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.0, bidirectional=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Размер входных признаков (128).\n",
    "            hidden_size (int): Размер скрытого состояния LSTM.\n",
    "            num_layers (int): Количество слоев LSTM.\n",
    "            dropout (float): Вероятность Dropout между слоями.\n",
    "            bidirectional (bool): Использовать_bidirectional LSTM.\n",
    "        \"\"\"\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_directions = 2 if bidirectional else 1\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        \n",
    "        # Если_bidirectional, добавляем слой для проекции выходов в нужный размер\n",
    "        if bidirectional:\n",
    "            self.output_projection = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        else:\n",
    "            self.output_projection = None\n",
    "            \n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and len(param.shape) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прогоняет вход через LSTM.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Входные данные [B, T_hist, input_size].\n",
    "            \n",
    "        Returns:\n",
    "            outputs (torch.Tensor): Все скрытые состояния [B, T_hist, hidden_size * num_directions].\n",
    "            (h_n, c_n) (tuple): Финальные скрытое и ячейковое состояния [num_layers * num_directions, B, hidden_size].\n",
    "        \"\"\"\n",
    "        outputs, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Если_bidirectional, проецируем выходы\n",
    "        if self.bidirectional:\n",
    "            outputs = self.output_projection(outputs)\n",
    "            \n",
    "        return outputs, (h_n, c_n)\n",
    "\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM Декодер с механизмом внимания для генерации прогноза.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, attention, dropout=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Размер входных признаков для декодера (обычно 1 - цена закрытия предыдущего шага).\n",
    "            hidden_size (int): Размер скрытого состояния LSTM декодера.\n",
    "            num_layers (int): Количество слоев LSTM декодера.\n",
    "            output_size (int): Размер выхода на каждом шаге (обычно 1).\n",
    "            attention (BahdanauAttention): Экземпляр механизма внимания.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        self.attention = attention\n",
    "        \n",
    "        # Вход декодера состоит из:\n",
    "        # 1. Предыдущий прогноз/таргет (input_size)\n",
    "        # 2. Контекстный вектор от внимания (attention.encoder_hidden_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size + attention.encoder_hidden_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        \n",
    "        # Полносвязный слой для преобразования выхода LSTM декодера в размер прогноза\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size + attention.encoder_hidden_dim, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and len(param.shape) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "\n",
    "    def forward(self, target_len, encoder_outputs, encoder_hidden, encoder_cell, teacher_forcing_ratio=0.5, targets=None, initial_input=None):\n",
    "        \"\"\"\n",
    "        Генерирует последовательность прогнозов.\n",
    "        \n",
    "        Args:\n",
    "            target_len (int): Длина последовательности для генерации (32).\n",
    "            encoder_outputs (torch.Tensor): Выходы энкодера [B, T_hist, H_enc].\n",
    "            encoder_hidden (torch.Tensor): Финальное скрытое состояние энкодера [num_layers_enc * num_directions, B, H_enc].\n",
    "            encoder_cell (torch.Tensor): Финальное ячейковое состояние энкодера [num_layers_enc * num_directions, B, H_enc].\n",
    "            teacher_forcing_ratio (float): Вероятность использования teacher forcing.\n",
    "            targets (torch.Tensor, optional): Реальные таргеты [B, T_pred, 1] для teacher forcing.\n",
    "            initial_input (torch.Tensor, optional): Начальное значение для декодера [B, 1, input_size].\n",
    "            \n",
    "        Returns:\n",
    "            outputs (torch.Tensor): Сгенерированные прогнозы [B, T_pred, output_size].\n",
    "            attention_weights_list (list): Список весов внимания для каждого шага [T_pred, B, T_hist].\n",
    "        \"\"\"\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        device = encoder_outputs.device\n",
    "        \n",
    "        # Инициализируем выходы декодера\n",
    "        outputs = torch.zeros(batch_size, target_len, self.output_size, device=device)\n",
    "        \n",
    "        # Инициализируем список для хранения весов внимания\n",
    "        attention_weights_list = []\n",
    "        \n",
    "        # Инициализируем вход декодера\n",
    "        if initial_input is not None:\n",
    "            decoder_input = initial_input # [B, 1, input_size]\n",
    "        else:\n",
    "            # Используем ноль как начальное значение\n",
    "            decoder_input = torch.zeros(batch_size, 1, 1, device=device) # [B, 1, 1]\n",
    "\n",
    "        # Инициализируем скрытое и ячейковое состояние декодера\n",
    "        # Берем последние num_layers слоев из encoder_hidden/encoder_cell\n",
    "        decoder_hidden = encoder_hidden[-self.num_layers:] if encoder_hidden.size(0) >= self.num_layers else encoder_hidden\n",
    "        decoder_cell = encoder_cell[-self.num_layers:] if encoder_cell.size(0) >= self.num_layers else encoder_cell\n",
    "        \n",
    "        for t in range(target_len):\n",
    "            # Вычисляем контекстный вектор с помощью внимания\n",
    "            context_vector, attention_weights = self.attention(encoder_outputs, decoder_hidden[-1])\n",
    "            attention_weights_list.append(attention_weights)\n",
    "            \n",
    "            # Подготовка входа для LSTM декодера\n",
    "            lstm_input = torch.cat((decoder_input, context_vector.unsqueeze(1)), dim=2)\n",
    "            \n",
    "            # Прогоняем через LSTM\n",
    "            lstm_output, (decoder_hidden, decoder_cell) = self.lstm(lstm_input, (decoder_hidden, decoder_cell))\n",
    "            \n",
    "            # Подготовка входа для полносвязного слоя\n",
    "            fc_input = torch.cat((lstm_output.squeeze(1), context_vector), dim=1)\n",
    "            \n",
    "            # Прогноз на текущем шаге\n",
    "            output = self.fc(fc_input)\n",
    "            outputs[:, t:t+1] = output.unsqueeze(1)\n",
    "            \n",
    "            # Подготовка decoder_input для следующего шага\n",
    "            use_teacher_forcing = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            if use_teacher_forcing and targets is not None and t < targets.size(1):\n",
    "                decoder_input = targets[:, t:t+1]\n",
    "            else:\n",
    "                decoder_input = output.unsqueeze(1)\n",
    "\n",
    "        return outputs, attention_weights_list\n",
    "\n",
    "\n",
    "\n",
    "class TradingLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Полная LSTM Encoder-Decoder модель с вниманием для прогнозирования цен.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size=128,\n",
    "        encoder_hidden_size=256,\n",
    "        encoder_num_layers=2,\n",
    "        decoder_hidden_size=256,\n",
    "        decoder_num_layers=2,\n",
    "        attention_dim=128,\n",
    "        target_len=32,\n",
    "        dropout=0.2,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        bidirectional_encoder=True,\n",
    "        use_layer_norm=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_size (int): Размер входных признаков после TradingProcessor (128).\n",
    "            encoder_hidden_size (int): Размер скрытого состояния энкодера.\n",
    "            encoder_num_layers (int): Количество слоев энкодера.\n",
    "            decoder_hidden_size (int): Размер скрытого состояния декодера.\n",
    "            decoder_num_layers (int): Количество слоев декодера.\n",
    "            attention_dim (int): Размер внутреннего представления внимания.\n",
    "            target_len (int): Длина прогнозируемой последовательности (32).\n",
    "            dropout (float): Вероятность Dropout.\n",
    "            teacher_forcing_ratio (float): Вероятность использования teacher forcing при обучении.\n",
    "            bidirectional_encoder (bool): Использовать_bidirectional LSTM в энкодере.\n",
    "            use_layer_norm (bool): Использовать Layer Normalization.\n",
    "        \"\"\"\n",
    "        super(TradingLSTM, self).__init__()\n",
    "        self.target_len = target_len\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        self.bidirectional_encoder = bidirectional_encoder\n",
    "        \n",
    "        # Создаем механизм внимания\n",
    "        self.attention = BahdanauAttention(\n",
    "            encoder_hidden_dim=encoder_hidden_size,\n",
    "            decoder_hidden_dim=decoder_hidden_size,\n",
    "            attention_dim=attention_dim\n",
    "        )\n",
    "        \n",
    "        # Создаем энкодер\n",
    "        self.encoder = LSTMEncoder(\n",
    "            input_size=feature_size,\n",
    "            hidden_size=encoder_hidden_size,\n",
    "            num_layers=encoder_num_layers,\n",
    "            dropout=dropout,\n",
    "            bidirectional=bidirectional_encoder\n",
    "        )\n",
    "        \n",
    "        # Создаем декодер\n",
    "        self.decoder = LSTMDecoder(\n",
    "            input_size=1, # Прогнозируемая цена закрытия\n",
    "            hidden_size=decoder_hidden_size,\n",
    "            num_layers=decoder_num_layers,\n",
    "            output_size=1, # Одна цена закрытия на выходе\n",
    "            attention=self.attention,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Дополнительный слой нормализации (опционально)\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        if use_layer_norm:\n",
    "            self.layer_norm = nn.LayerNorm(feature_size)\n",
    "            \n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and len(param.shape) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Исторические данные после обработки [B, T_hist, F_hist=128].\n",
    "            tgt (torch.Tensor, optional): Целевые значения (таргеты) [B, T_pred, 1]. Используется для teacher forcing.\n",
    "            \n",
    "        Returns:\n",
    "            output (torch.Tensor): Прогнозы [B, T_pred, 1].\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        \n",
    "        # Применяем Layer Normalization (если включено)\n",
    "        if self.use_layer_norm:\n",
    "            src = self.layer_norm(src)\n",
    "        \n",
    "        # 1. Энкодер\n",
    "        encoder_outputs, (encoder_hidden, encoder_cell) = self.encoder(src)\n",
    "        \n",
    "        # 2. Подготовка начального значения для декодера\n",
    "        # Можно использовать последнее значение цены закрытия из исходных данных\n",
    "        # Предполагаем, что цена закрытия - это 4-й столбец в исходных данных (до обработки)\n",
    "        # Но так как у нас уже обработанные данные, можно использовать среднее или другое значение\n",
    "        # Для простоты возьмем среднее значение последних N точек\n",
    "        # initial_input = src[:, -1:, 3:4] # Если бы у нас были исходные данные\n",
    "        # Или просто ноль\n",
    "        initial_input = None # Пусть декодер сам решит\n",
    "        \n",
    "        # 3. Декодер\n",
    "        decoder_outputs, _ = self.decoder(\n",
    "            target_len=self.target_len,\n",
    "            encoder_outputs=encoder_outputs,\n",
    "            encoder_hidden=encoder_hidden,\n",
    "            encoder_cell=encoder_cell,\n",
    "            teacher_forcing_ratio=self.teacher_forcing_ratio if self.training else 0.0,\n",
    "            targets=tgt,\n",
    "            initial_input=initial_input\n",
    "        )\n",
    "        \n",
    "        return decoder_outputs\n",
    "\n",
    "\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры модели\n",
    "    B, T_hist, feature_size = 4, 256, 128\n",
    "    T_pred = 32\n",
    "    output_size = 1\n",
    "    \n",
    "    # Создание модели\n",
    "    model = TradingLSTM(\n",
    "        feature_size=feature_size,\n",
    "        encoder_hidden_size=512,\n",
    "        encoder_num_layers=3,\n",
    "        decoder_hidden_size=512,\n",
    "        decoder_num_layers=3,\n",
    "        attention_dim=128,\n",
    "        target_len=T_pred,\n",
    "        dropout=0.2,\n",
    "        teacher_forcing_ratio=0.5,\n",
    "        bidirectional_encoder=True, # Новое улучшение\n",
    "        use_layer_norm=True # Новое улучшение\n",
    "    )\n",
    "    \n",
    "    # Примерные входные данные\n",
    "    src = torch.randn(B, T_hist, feature_size)  # История после TradingProcessor\n",
    "    tgt = torch.randn(B, T_pred, output_size)   # Целевые значения\n",
    "    \n",
    "    # Обучение (с учителем)\n",
    "    model.train()\n",
    "    output_train = model(src, tgt)\n",
    "    print(f\"Выход при обучении (с учителем): {output_train.shape}\") # [B, 32, 1]\n",
    "    \n",
    "    # Инференс\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_infer = model(src)\n",
    "        print(f\"Выход при инференсе: {output_infer.shape}\") # [B, 32, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99832a",
   "metadata": {},
   "source": [
    "### Temporal Convolutional Network (TCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8713f2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход модели: torch.Size([4, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Chomp1d(nn.Module):\n",
    "    \"\"\"\n",
    "    Отсекает лишние элементы из последовательности после свертки с паддингом.\n",
    "    Обеспечивает причинность (causality) свертки.\n",
    "    \"\"\"\n",
    "    def __init__(self, chomp_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chomp_size (int): Количество элементов для отсечения с правого края.\n",
    "        \"\"\"\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, C, T]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, C, T - chomp_size]\n",
    "        \"\"\"\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "\n",
    "\n",
    "\n",
    "class TemporalBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Базовый блок TCN: две причинные свертки с Dilated Conv + ReLU + Dropout.\n",
    "    Использует остаточные соединения.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            n_inputs (int): Количество входных каналов.\n",
    "            n_outputs (int): Количество выходных каналов.\n",
    "            kernel_size (int): Размер ядра свертки.\n",
    "            stride (int): Шаг свертки.\n",
    "            dilation (int): Коэффициент расширения (dilation).\n",
    "            padding (int): Размер паддинга.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        \n",
    "        # Первый сверточный слой\n",
    "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                               stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)  # Убираем паддинг, чтобы сохранить причинность\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "\n",
    "        # Второй сверточный слой\n",
    "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                               stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "        # Последовательность для первого блока\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "\n",
    "        # Слой проекции для остаточного соединения, если размерности не совпадают\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.init_weights()\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Инициализация весов сверточных слоев.\"\"\"\n",
    "        # Инициализация для conv1\n",
    "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.conv1.bias is not None:\n",
    "            nn.init.constant_(self.conv1.bias, 0)\n",
    "            \n",
    "        # Инициализация для conv2\n",
    "        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.conv2.bias is not None:\n",
    "            nn.init.constant_(self.conv2.bias, 0)\n",
    "            \n",
    "        # Инициализация слоя проекции (если он есть)\n",
    "        if self.downsample is not None:\n",
    "            nn.init.kaiming_normal_(self.downsample.weight, mode='fan_out', nonlinearity='relu')\n",
    "            if self.downsample.bias is not None:\n",
    "                nn.init.constant_(self.downsample.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямой проход через блок.\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, n_inputs, T]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, n_outputs, T]\n",
    "        \"\"\"\n",
    "        out = self.net(x)\n",
    "        # Остаточное соединение\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Полная TCN архитектура, состоящая из стека TemporalBlock'ов.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_inputs (int): Количество входных признаков.\n",
    "            num_channels (list): Список количества каналов для каждого блока.\n",
    "                             Например, [256, 256, 256] означает 3 блока по 256 каналов.\n",
    "            kernel_size (int): Размер ядра свертки.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        \n",
    "        for i in range(num_levels):\n",
    "            # Вычисляем параметры для текущего блока\n",
    "            dilation_size = 2 ** i  # Экспоненциально увеличиваем dilation\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            \n",
    "            # Добавляем блок\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, \n",
    "                                   dilation=dilation_size, padding=(kernel_size-1) * dilation_size, \n",
    "                                   dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямой проход через всю сеть.\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, num_inputs, T]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, num_channels[-1], T]\n",
    "        \"\"\"\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "\n",
    "class TradingTCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Полная модель TCN для прогнозирования цен на фондовом рынке.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size=128,           # Размер признаков от TradingProcessor\n",
    "        num_channels=[64, 64, 64, 128, 128, 128, 256, 256, 512, 512], # Архитектура TCN\n",
    "        kernel_size=3,              # Размер ядра свертки\n",
    "        dropout=0.2,                # Dropout\n",
    "        target_len=32,              # Длина прогноза\n",
    "        use_layer_norm=True,        # Использовать LayerNorm\n",
    "        use_weight_norm=True        # Использовать WeightNorm\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_size (int): Размер входных признаков (128).\n",
    "            num_channels (list): Список количества каналов для каждого TCN блока.\n",
    "            kernel_size (int): Размер ядра свертки.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "            target_len (int): Длина прогнозируемой последовательности (32).\n",
    "            use_layer_norm (bool): Применять ли LayerNorm к входу.\n",
    "            use_weight_norm (bool): Применять ли WeightNorm к сверточным слоям.\n",
    "        \"\"\"\n",
    "        super(TradingTCN, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.target_len = target_len\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        self.use_weight_norm = use_weight_norm\n",
    "        \n",
    "        # LayerNorm для нормализации входа\n",
    "        if use_layer_norm:\n",
    "            self.layer_norm = nn.LayerNorm(feature_size)\n",
    "        \n",
    "        # TCN сеть\n",
    "        self.tcn = TemporalConvNet(feature_size, num_channels, kernel_size=kernel_size, dropout=dropout)\n",
    "        \n",
    "        # Выходной слой для прогнозирования\n",
    "        # Вход: [B, num_channels[-1], T_hist]\n",
    "        # Выход: [B, 1, T_hist] (прогнозируем только цену закрытия)\n",
    "        self.output_projection = nn.Conv1d(num_channels[-1], 1, 1) # 1x1 conv для проекции каналов\n",
    "        \n",
    "        # Дополнительный слой для генерации последовательности прогноза\n",
    "        # Мы можем использовать последние target_len точек из выхода TCN\n",
    "        # или применить дополнительную обработку\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        # Применяем WeightNorm, если требуется\n",
    "        if use_weight_norm:\n",
    "            self.apply_weight_norm()\n",
    "            \n",
    "\n",
    "    def apply_weight_norm(self):\n",
    "        \"\"\"Применяет WeightNorm к сверточным слоям.\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Conv1d, nn.ConvTranspose1d)):\n",
    "                module = nn.utils.weight_norm(module)\n",
    "\n",
    "\n",
    "    def init_weights(self):\n",
    "        \"\"\"Инициализация весов выходного слоя.\"\"\"\n",
    "        nn.init.kaiming_normal_(self.output_projection.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if self.output_projection.bias is not None:\n",
    "            nn.init.constant_(self.output_projection.bias, 0)\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Исторические данные [B, T_hist, F_hist=128].\n",
    "                                Должны быть уже обработаны TradingProcessor.\n",
    "            tgt (torch.Tensor, optional): Целевые значения [B, T_pred, 1].\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Прогнозы [B, T_pred, 1].\n",
    "        \"\"\"\n",
    "        # src: [B, T_hist, 128]\n",
    "        batch_size, seq_len, _ = src.size()\n",
    "        \n",
    "        # Применяем Layer Normalization (если включено)\n",
    "        if self.use_layer_norm:\n",
    "            src = self.layer_norm(src) # [B, T_hist, 128]\n",
    "            \n",
    "        # Переставляем размерности для TCN: [B, F_hist, T_hist]\n",
    "        x = src.transpose(1, 2).contiguous() # [B, 128, T_hist]\n",
    "        \n",
    "        # Пропускаем через TCN\n",
    "        # y: [B, num_channels[-1], T_hist]\n",
    "        y = self.tcn(x)\n",
    "        \n",
    "        # Применяем выходную проекцию для получения прогноза цены закрытия\n",
    "        # output: [B, 1, T_hist]\n",
    "        output = self.output_projection(y)\n",
    "        \n",
    "        # Берем последние target_len точек для прогноза\n",
    "        # output: [B, 1, T_hist] -> [B, 1, target_len] -> [B, target_len, 1]\n",
    "        prediction = output[:, :, -self.target_len:].transpose(1, 2)\n",
    "        \n",
    "        return prediction\n",
    "\n",
    "\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры модели\n",
    "    B, T_hist, feature_size = 4, 256, 128\n",
    "    T_pred = 32\n",
    "    output_size = 1\n",
    "    \n",
    "    # Создание модели\n",
    "    model = TradingTCN(\n",
    "        feature_size=feature_size,\n",
    "        num_channels=[64, 64, 128, 128, 256, 256, 512, 512], # Глубокая архитектура\n",
    "        kernel_size=3,\n",
    "        dropout=0.2,\n",
    "        target_len=T_pred,\n",
    "        use_layer_norm=True,\n",
    "        use_weight_norm=True\n",
    "    )\n",
    "    \n",
    "    # Примерные входные данные\n",
    "    src = torch.randn(B, T_hist, feature_size)  # История после TradingProcessor\n",
    "    tgt = torch.randn(B, T_pred, output_size)   # Целевые значения (опционально)\n",
    "    \n",
    "    # Прогон модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(src, tgt)\n",
    "        print(f\"Выход модели: {output.shape}\") # [B, 32, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f9b0e3",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30b5fe79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход модели: torch.Size([4, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BottleneckBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck блок ResNet, как в ResNet-50/101/152.\n",
    "    Состоит из 1x1 -> 3x3 -> 1x1 сверток.\n",
    "    \"\"\"\n",
    "    expansion = 4  # Коэффициент увеличения размера выхода по каналам\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels (int): Количество входных каналов.\n",
    "            out_channels (int): Количество выходных каналов (до expansion).\n",
    "            stride (int): Шаг свертки (используется в 3x3 свертке для downsampling).\n",
    "            downsample (nn.Module, optional): Слой для проекции shortcut, если необходимо.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(BottleneckBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, \n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        \n",
    "        # Третья свертка увеличивает количество каналов в expansion раз\n",
    "        self.conv3 = nn.Conv1d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm1d(out_channels * self.expansion)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, C_in, T]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, C_out_expanded, T]\n",
    "        \"\"\"\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        \n",
    "        # Применяем downsampling к shortcut, если необходимо\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # Остаточное соединение\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNetCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-подобная CNN для обработки временных рядов.\n",
    "    Адаптирована для 1D данных (временные ряды).\n",
    "    \"\"\"\n",
    "    def __init__(self, block, layers, input_channels=128, num_classes=32, dropout=0.2):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            block (nn.Module): Тип блока (BottleneckBlock).\n",
    "            layers (list): Список, определяющий количество блоков в каждом слое.\n",
    "                          Например, [3, 4, 23, 3] для ResNet-101.\n",
    "            input_channels (int): Количество входных признаков (128 от TradingProcessor).\n",
    "            num_classes (int): Размерность выхода (32 точки прогноза).\n",
    "            dropout (float): Вероятность Dropout в голове.\n",
    "        \"\"\"\n",
    "        super(ResNetCNN, self).__init__()\n",
    "        self.in_channels = 64  # Начальное количество каналов\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # Начальный слой для преобразования входа в последовательность признаков\n",
    "        # Предполагаем, что вход [B, T, F] -> [B, F, T] для Conv1d\n",
    "        # Но мы хотим обрабатывать временные зависимости, поэтому свертка по времени\n",
    "        # Для этого вход будет [B, F_in, T], где F_in=128, T=256\n",
    "        # Начальный conv1d преобразует F_in -> 64 признаков\n",
    "        self.conv1 = nn.Conv1d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # Создаем слои ResNet\n",
    "        # Для 1D данные, \"layer1\" не делает downsampling (stride=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], dropout=dropout)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dropout=dropout)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dropout=dropout)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dropout=dropout)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1) # Глобальный average pooling\n",
    "        \n",
    "        # Голова для прогнозирования\n",
    "        # После layer4 у нас будет 512 * expansion = 512 * 4 = 2048 каналов\n",
    "        self.fc_head = nn.Sequential(\n",
    "            nn.Linear(512 * block.expansion, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(512, num_classes) # Выход [B, 32]\n",
    "        )\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self._init_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, blocks, stride=1, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Создает слой ResNet, состоящий из нескольких bottleneck блоков.\n",
    "        \"\"\"\n",
    "        downsample = None\n",
    "        # Если stride != 1 или количество каналов изменилось, нужна проекция shortcut\n",
    "        if stride != 1 or self.in_channels != out_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv1d(self.in_channels, out_channels * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        # Первый блок может делать downsampling\n",
    "        layers.append(block(self.in_channels, out_channels, stride, downsample, dropout))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        # Остальные блоки без downsampling\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels, dropout=dropout))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Прямой проход.\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, F_in=128, T=256]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, num_classes=32]\n",
    "        \"\"\"\n",
    "        # x: [B, 128, 256]\n",
    "        x = self.conv1(x)       # [B, 64, 128]\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)     # [B, 64, 64]\n",
    "\n",
    "        x = self.layer1(x)      # [B, 256, 64]  (64 = 64 * 4)\n",
    "        x = self.layer2(x)      # [B, 512, 32]  (512 = 128 * 4)\n",
    "        x = self.layer3(x)      # [B, 1024, 16] (1024 = 256 * 4)\n",
    "        x = self.layer4(x)      # [B, 2048, 8]  (2048 = 512 * 4)\n",
    "\n",
    "        # Глобальный average pooling: [B, 2048, 8] -> [B, 2048, 1] -> [B, 2048]\n",
    "        x = self.avgpool(x).view(x.size(0), -1)\n",
    "        \n",
    "        # Голова прогнозирования: [B, 2048] -> [B, 32]\n",
    "        x = self.fc_head(x)\n",
    "        \n",
    "        # Добавляем размерность для совместимости с другими моделями [B, 32] -> [B, 32, 1]\n",
    "        x = x.unsqueeze(-1)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class TradingCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Мощная CNN модель на основе ResNet-101 для прогнозирования цен на фондовом рынке.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size=128,           # Размер признаков от TradingProcessor\n",
    "        target_len=32,              # Длина прогноза\n",
    "        dropout=0.2,                # Dropout\n",
    "        use_layer_norm=True,        # Использовать LayerNorm на входе\n",
    "        resnet_layers=[3, 4, 23, 3] # Конфигурация слоев ResNet (ResNet-101)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_size (int): Размер входных признаков (128).\n",
    "            target_len (int): Длина прогнозируемой последовательности (32).\n",
    "            dropout (float): Вероятность Dropout.\n",
    "            use_layer_norm (bool): Применять ли LayerNorm к входу.\n",
    "            resnet_layers (list): Конфигурация слоев ResNet.\n",
    "        \"\"\"\n",
    "        super(TradingCNN, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.target_len = target_len\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        \n",
    "        # LayerNorm для нормализации входа\n",
    "        if use_layer_norm:\n",
    "            self.layer_norm = nn.LayerNorm(feature_size)\n",
    "            \n",
    "        # Основная ResNet-подобная CNN\n",
    "        self.resnet_cnn = ResNetCNN(\n",
    "            block=BottleneckBlock,\n",
    "            layers=resnet_layers, # [3, 4, 23, 3] для ResNet-101\n",
    "            input_channels=feature_size,\n",
    "            num_classes=target_len,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Исторические данные [B, T_hist=256, F_hist=128].\n",
    "                                Должны быть уже обработаны TradingProcessor.\n",
    "            tgt (torch.Tensor, optional): Целевые значения [B, T_pred, 1].\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Прогнозы [B, T_pred=32, 1].\n",
    "        \"\"\"\n",
    "        # src: [B, 256, 128]\n",
    "        batch_size, seq_len, _ = src.size()\n",
    "        \n",
    "        # Применяем Layer Normalization (если включено)\n",
    "        if self.use_layer_norm:\n",
    "            src = self.layer_norm(src) # [B, 256, 128]\n",
    "            \n",
    "        # Переставляем размерности для CNN: [B, F_hist, T_hist]\n",
    "        x = src.transpose(1, 2).contiguous() # [B, 128, 256]\n",
    "        \n",
    "        # Пропускаем через ResNet CNN\n",
    "        # y: [B, 32, 1]\n",
    "        y = self.resnet_cnn(x)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры модели\n",
    "    B, T_hist, feature_size = 4, 256, 128\n",
    "    T_pred = 32\n",
    "    output_size = 1\n",
    "    \n",
    "    # Создание модели (ResNet-101)\n",
    "    model = TradingCNN(\n",
    "        feature_size=feature_size,\n",
    "        target_len=T_pred,\n",
    "        dropout=0.2,\n",
    "        use_layer_norm=True,\n",
    "        resnet_layers=[3, 4, 23, 3] # ResNet-101\n",
    "    ).to('mps')\n",
    "    \n",
    "    # Примерные входные данные\n",
    "    src = torch.randn(B, T_hist, feature_size).to('mps')  # История после TradingProcessor\n",
    "    tgt = torch.randn(B, T_pred, output_size).to('mps')   # Целевые значения (опционально)\n",
    "    \n",
    "    # Прогон модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(src, tgt)\n",
    "        print(f\"Выход модели: {output.shape}\") # [B, 32, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c859306",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa7f82d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход при инференсе (авторегрессивно): torch.Size([4, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Позиционное кодирование для добавления информации о позиции в последовательности.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): Размерность модели (признаков).\n",
    "            max_len (int): Максимальная длина последовательности.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Создаем матрицу позиционных кодировок: [max_len, d_model]\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1) # [max_len, 1]\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)  # Even indices\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)  # Odd indices\n",
    "        \n",
    "        # Добавляем размерность для батча: [1, max_len, d_model]\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # Регистрируем как буфер, чтобы он сохранялся при сериализации модели\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, seq_len, d_model]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # x: [B, seq_len, d_model]\n",
    "        # self.pe: [1, max_len, d_model]\n",
    "        x = x + self.pe[:, :x.size(1)] # Broadcasting по батчу\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Многоголовое внимание (Multi-Head Attention).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): Размерность модели.\n",
    "            num_heads (int): Количество голов внимания.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads # Размерность ключа/запроса/значения на одну голову\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = math.sqrt(self.d_k)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (Tensor): Запросы [B, len_q, d_model]\n",
    "            key (Tensor): Ключи [B, len_k, d_model]\n",
    "            value (Tensor): Значения [B, len_v, d_model]\n",
    "            mask (Tensor, optional): Маска [B, 1, len_q, len_k] или [B, num_heads, len_q, len_k]\n",
    "        Returns:\n",
    "            Tensor: Выход [B, len_q, d_model]\n",
    "            Tensor: Веса внимания [B, num_heads, len_q, len_k]\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Линейные преобразования и разделение на головы\n",
    "        # [B, len, d_model] -> [B, len, num_heads, d_k] -> [B, num_heads, len, d_k]\n",
    "        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Матрица оценок внимания\n",
    "        # [B, num_heads, len_q, d_k] x [B, num_heads, d_k, len_k] -> [B, num_heads, len_q, len_k]\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n",
    "\n",
    "        # Применение маски (если есть)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        # Вычисление весов внимания\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Применение весов к значениям\n",
    "        # [B, num_heads, len_q, len_k] x [B, num_heads, len_v, d_k] -> [B, num_heads, len_q, d_k]\n",
    "        # len_k == len_v\n",
    "        attn_output = torch.matmul(attn_weights, V)\n",
    "\n",
    "        # Конкатенация голов и линейное преобразование\n",
    "        # [B, num_heads, len_q, d_k] -> [B, len_q, num_heads, d_k] -> [B, len_q, d_model]\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        output = self.W_o(attn_output)\n",
    "\n",
    "        return output, attn_weights\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Позиционно-независимый полносвязный слой (Feed-Forward Network).\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): Размерность модели.\n",
    "            d_ff (int): Размерность внутреннего слоя.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Входной тензор [B, seq_len, d_model]\n",
    "        Returns:\n",
    "            Tensor: Выходной тензор [B, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Блок энкодера: Multi-Head Attention + Feed Forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): Размерность модели.\n",
    "            num_heads (int): Количество голов внимания.\n",
    "            d_ff (int): Размерность внутреннего слоя FFN.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src (Tensor): Входные данные [B, seq_len, d_model]\n",
    "            src_mask (Tensor, optional): Маска для внимания [B, 1, 1, seq_len] или подобная\n",
    "        Returns:\n",
    "            Tensor: Выходные данные [B, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        # Self-attention\n",
    "        attn_out, _ = self.self_attn(src, src, src, src_mask)\n",
    "        src = self.norm1(src + self.dropout1(attn_out))\n",
    "        \n",
    "        # Feed forward\n",
    "        ffn_out = self.ffn(src)\n",
    "        out = self.norm2(src + self.dropout2(ffn_out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Блок декодера: Masked Multi-Head Attention + Multi-Head Attention + Feed Forward.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model (int): Размерность модели.\n",
    "            num_heads (int): Количество голов внимания.\n",
    "            d_ff (int): Размерность внутреннего слоя FFN.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.ffn = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tgt (Tensor): Вход декодера (таргеты) [B, tgt_len, d_model]\n",
    "            memory (Tensor): Выход энкодера [B, src_len, d_model]\n",
    "            tgt_mask (Tensor, optional): Маска для self-attention в декодере [B, 1, tgt_len, tgt_len]\n",
    "            memory_mask (Tensor, optional): Маска для cross-attention [B, 1, 1, src_len]\n",
    "        Returns:\n",
    "            Tensor: Выход декодера [B, tgt_len, d_model]\n",
    "        \"\"\"\n",
    "        # Masked self-attention (causal)\n",
    "        self_attn_out, _ = self.self_attn(tgt, tgt, tgt, tgt_mask)\n",
    "        tgt = self.norm1(tgt + self.dropout1(self_attn_out))\n",
    "        \n",
    "        # Cross-attention\n",
    "        cross_attn_out, _ = self.cross_attn(tgt, memory, memory, memory_mask)\n",
    "        tgt = self.norm2(tgt + self.dropout2(cross_attn_out))\n",
    "        \n",
    "        # Feed forward\n",
    "        ffn_out = self.ffn(tgt)\n",
    "        out = self.norm3(tgt + self.dropout3(ffn_out))\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Полный энкодер трансформера.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_layers (int): Количество блоков энкодера.\n",
    "            d_model (int): Размерность модели.\n",
    "            num_heads (int): Количество голов внимания.\n",
    "            d_ff (int): Размерность внутреннего слоя FFN.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderBlock(d_model, num_heads, d_ff, dropout) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src (Tensor): Входные данные [B, src_len, d_model]\n",
    "            src_mask (Tensor, optional): Маска для внимания [B, 1, 1, src_len]\n",
    "        Returns:\n",
    "            Tensor: Выходные данные [B, src_len, d_model]\n",
    "        \"\"\"\n",
    "        output = src\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, src_mask)\n",
    "        return self.norm(output)\n",
    "\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Полный декодер трансформера.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_layers (int): Количество блоков декодера.\n",
    "            d_model (int): Размерность модели.\n",
    "            num_heads (int): Количество голов внимания.\n",
    "            d_ff (int): Размерность внутреннего слоя FFN.\n",
    "            dropout (float): Вероятность Dropout.\n",
    "        \"\"\"\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(d_model, num_heads, d_ff, dropout) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None, memory_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tgt (Tensor): Вход декодера (таргеты) [B, tgt_len, d_model]\n",
    "            memory (Tensor): Выход энкодера [B, src_len, d_model]\n",
    "            tgt_mask (Tensor, optional): Маска для self-attention в декодере [B, 1, tgt_len, tgt_len]\n",
    "            memory_mask (Tensor, optional): Маска для cross-attention [B, 1, 1, src_len]\n",
    "        Returns:\n",
    "            Tensor: Выход декодера [B, tgt_len, d_model]\n",
    "        \"\"\"\n",
    "        output = tgt\n",
    "        for layer in self.layers:\n",
    "            output = layer(output, memory, tgt_mask, memory_mask)\n",
    "        return self.norm(output)\n",
    "\n",
    "\n",
    "class TradingTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Полная модель Transformer для прогнозирования цен на фондовом рынке.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size=128,           # Размер признаков от TradingProcessor\n",
    "        d_model=512,                # Размерность внутреннего представления\n",
    "        num_encoder_layers=6,       # Количество слоев в энкодере\n",
    "        num_decoder_layers=6,       # Количество слоев в декодере\n",
    "        num_heads=8,                # Количество голов внимания\n",
    "        d_ff=2048,                  # Размерность внутреннего слоя FFN\n",
    "        target_len=32,              # Длина прогноза\n",
    "        dropout=0.1,                # Dropout\n",
    "        use_layer_norm=True,        # Использовать LayerNorm на входе\n",
    "        max_seq_len=1000            # Максимальная длина последовательности для поз. кодирования\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_size (int): Размер входных признаков (128).\n",
    "            d_model (int): Размерность внутреннего представления модели.\n",
    "            num_encoder_layers (int): Количество слоев в энкодере.\n",
    "            num_decoder_layers (int): Количество слоев в декодере.\n",
    "            num_heads (int): Количество голов внимания.\n",
    "            d_ff (int): Размерность внутреннего слоя FFN.\n",
    "            target_len (int): Длина прогнозируемой последовательности (32).\n",
    "            dropout (float): Вероятность Dropout.\n",
    "            use_layer_norm (bool): Применять ли LayerNorm к входу.\n",
    "            max_seq_len (int): Максимальная длина последовательности для поз. кодирования.\n",
    "        \"\"\"\n",
    "        super(TradingTransformer, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.d_model = d_model\n",
    "        self.target_len = target_len\n",
    "        self.use_layer_norm = use_layer_norm\n",
    "        \n",
    "        # Входные эмбеддинги и позиционное кодирование\n",
    "        # Для истории\n",
    "        self.src_embedding = nn.Linear(feature_size, d_model)\n",
    "        # Для таргетов (предполагаем, что таргет это цена закрытия, 1 признак)\n",
    "        self.tgt_embedding = nn.Linear(1, d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_len, dropout)\n",
    "        \n",
    "        # LayerNorm для нормализации входа (опционально)\n",
    "        if use_layer_norm:\n",
    "            self.src_layer_norm = nn.LayerNorm(feature_size)\n",
    "            self.tgt_layer_norm = nn.LayerNorm(1) # Таргет это 1 признак\n",
    "            \n",
    "        # Энкодер и Декодер\n",
    "        self.encoder = TransformerEncoder(\n",
    "            num_layers=num_encoder_layers,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.decoder = TransformerDecoder(\n",
    "            num_layers=num_decoder_layers,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            d_ff=d_ff,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Выходной слой для прогнозирования\n",
    "        # Проектируем из d_model в размерность таргета (1)\n",
    "        self.output_projection = nn.Linear(d_model, 1)\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов.\"\"\"\n",
    "        for name, param in self.named_parameters():\n",
    "            if 'weight' in name and len(param.shape) > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:\n",
    "                nn.init.constant_(param, 0)\n",
    "\n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"\n",
    "        Генерирует квадратную маску для предотвращения заглядывания в будущее.\n",
    "        Args:\n",
    "            sz (int): Размер квадратной матрицы.\n",
    "        Returns:\n",
    "            Tensor: Маска [sz, sz] с 0 для запрещенных позиций и -inf для разрешенных.\n",
    "        \"\"\"\n",
    "        mask = torch.triu(torch.ones(sz, sz), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    def _prepare_encoder_input(self, src):\n",
    "        \"\"\"Подготовка входа для энкодера.\"\"\"\n",
    "        batch_size, src_seq_len, _ = src.size()\n",
    "        \n",
    "        # Применяем Layer Normalization (если включено)\n",
    "        if self.use_layer_norm:\n",
    "            src_norm = self.src_layer_norm(src) # [B, src_seq_len, 128]\n",
    "        else:\n",
    "            src_norm = src\n",
    "            \n",
    "        # Линейное преобразование в d_model\n",
    "        src_embedded = self.src_embedding(src_norm) # [B, src_seq_len, d_model]\n",
    "        \n",
    "        # Добавляем позиционное кодирование\n",
    "        src_embedded = self.positional_encoding(src_embedded) # [B, src_seq_len, d_model]\n",
    "        \n",
    "        return src_embedded\n",
    "\n",
    "    def _prepare_decoder_input(self, tgt):\n",
    "        \"\"\"Подготовка входа для декодера.\"\"\"\n",
    "        batch_size, tgt_seq_len, _ = tgt.size()\n",
    "        \n",
    "        # Применяем Layer Normalization к таргету (если включено)\n",
    "        if self.use_layer_norm:\n",
    "            tgt_norm = self.tgt_layer_norm(tgt) # [B, tgt_seq_len, 1]\n",
    "        else:\n",
    "            tgt_norm = tgt\n",
    "            \n",
    "        # Линейное преобразование в d_model\n",
    "        tgt_embedded = self.tgt_embedding(tgt_norm) # [B, tgt_seq_len, d_model]\n",
    "        \n",
    "        # Добавляем позиционное кодирование\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded) # [B, tgt_seq_len, d_model]\n",
    "        \n",
    "        return tgt_embedded\n",
    "\n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Исторические данные [B, T_hist=256, F_hist=128].\n",
    "                                Должны быть уже обработаны TradingProcessor.\n",
    "            tgt (torch.Tensor, optional): Целевые значения [B, T_pred=32, 1].\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Прогнозы [B, T_pred=32, 1].\n",
    "        \"\"\"\n",
    "        # src: [B, 256, 128]\n",
    "        # tgt: [B, 32, 1] (если предоставлено)\n",
    "        \n",
    "        # --- Обработка входа (энкодер) ---\n",
    "        src_embedded = self._prepare_encoder_input(src)\n",
    "        \n",
    "        # Пропускаем через энкодер\n",
    "        # memory: [B, 256, d_model]\n",
    "        memory = self.encoder(src_embedded)\n",
    "        \n",
    "        # --- Обработка таргета (декодер) ---\n",
    "        if self.training or tgt is not None:\n",
    "            # Во время обучения используем предоставленные таргеты (teacher forcing)\n",
    "            if tgt is None:\n",
    "                raise ValueError(\"tgt must be provided during training\")\n",
    "                \n",
    "            tgt_input = tgt # [B, 32, 1]\n",
    "            tgt_embedded = self._prepare_decoder_input(tgt_input)\n",
    "            \n",
    "            # Генерируем маску для предотвращения заглядывания в будущее\n",
    "            tgt_seq_len = tgt_embedded.size(1)\n",
    "            tgt_mask = self.generate_square_subsequent_mask(tgt_seq_len).to(tgt_embedded.device)\n",
    "            # tgt_mask: [tgt_seq_len, tgt_seq_len] -> [1, 1, tgt_seq_len, tgt_seq_len]\n",
    "            tgt_mask = tgt_mask.unsqueeze(0).unsqueeze(0)\n",
    "            \n",
    "            # Пропускаем через декодер\n",
    "            # decoder_output: [B, 32, d_model]\n",
    "            decoder_output = self.decoder(\n",
    "                tgt=tgt_embedded,\n",
    "                memory=memory,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            \n",
    "            # Применяем выходную проекцию\n",
    "            # output: [B, 32, d_model] -> [B, 32, 1]\n",
    "            output = self.output_projection(decoder_output)\n",
    "            \n",
    "        else:\n",
    "            # Во время инференса генерируем таргеты авторегрессивно\n",
    "            output = self.generate(src, memory)\n",
    "            \n",
    "        return output\n",
    "\n",
    "    def generate(self, src, memory=None):\n",
    "        \"\"\"\n",
    "        Авторегрессивная генерация прогноза.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Исторические данные [B, T_hist, F_hist].\n",
    "            memory (torch.Tensor, optional): Предвычисленный выход энкодера [B, T_hist, d_model].\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Прогнозы [B, T_pred, 1].\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        device = src.device\n",
    "        \n",
    "        if memory is None:\n",
    "            # Вычисляем memory, если оно не предоставлено\n",
    "            src_embedded = self._prepare_encoder_input(src)\n",
    "            memory = self.encoder(src_embedded)\n",
    "        \n",
    "        # Начинаем с токена начала последовательности или последнего известного значения\n",
    "        # Для простоты начнем с нулей\n",
    "        # tgt: [B, 1, 1] - начинаем с одного токена\n",
    "        tgt = torch.zeros(batch_size, 1, 1, device=device)\n",
    "        \n",
    "        # Список для хранения прогнозов\n",
    "        predictions = []\n",
    "        \n",
    "        for _ in range(self.target_len):\n",
    "            # Подготавливаем текущий tgt для декодера\n",
    "            tgt_embedded = self._prepare_decoder_input(tgt) # [B, текущая_длина, d_model]\n",
    "            \n",
    "            # Генерируем маску для текущей длины\n",
    "            current_tgt_len = tgt_embedded.size(1)\n",
    "            tgt_mask = self.generate_square_subsequent_mask(current_tgt_len).to(device)\n",
    "            tgt_mask = tgt_mask.unsqueeze(0).unsqueeze(0) # [1, 1, текущая_длина, текущая_длина]\n",
    "            \n",
    "            # Пропускаем через декодер\n",
    "            # decoder_output: [B, текущая_длина, d_model]\n",
    "            decoder_output = self.decoder(\n",
    "                tgt=tgt_embedded,\n",
    "                memory=memory,\n",
    "                tgt_mask=tgt_mask\n",
    "            )\n",
    "            \n",
    "            # Берем выход последнего токена (наш прогноз)\n",
    "            # last_output: [B, d_model]\n",
    "            last_output = decoder_output[:, -1, :]\n",
    "            \n",
    "            # Применяем выходную проекцию\n",
    "            # next_prediction: [B, 1]\n",
    "            next_prediction = self.output_projection(last_output)\n",
    "            predictions.append(next_prediction.unsqueeze(1)) # [B, 1, 1]\n",
    "            \n",
    "            # Обновляем tgt для следующей итерации\n",
    "            # Добавляем прогноз к tgt\n",
    "            # tgt: [B, текущая_длина, 1]\n",
    "            # next_prediction.unsqueeze(1): [B, 1, 1]\n",
    "            tgt = torch.cat([tgt, next_prediction.unsqueeze(1)], dim=1) # [B, текущая_длина+1, 1]\n",
    "            \n",
    "        # Конкатенируем все прогнозы\n",
    "        # Каждый элемент predictions: [B, 1, 1]\n",
    "        # final_output: [B, T_pred, 1]\n",
    "        final_output = torch.cat(predictions, dim=1)\n",
    "        \n",
    "        return final_output\n",
    "\n",
    "\n",
    "\n",
    "# --- Пример использования ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры модели\n",
    "    B, T_hist, feature_size = 4, 256, 128 # Уменьшено B для теста\n",
    "    T_pred = 32\n",
    "    output_size = 1\n",
    "    \n",
    "    # Создание модели\n",
    "    model = TradingTransformer(\n",
    "        feature_size=feature_size,\n",
    "        d_model=512, \n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        num_heads=8, \n",
    "        d_ff=2048, \n",
    "        target_len=T_pred,\n",
    "        dropout=0.1,\n",
    "        use_layer_norm=True,\n",
    "        max_seq_len=1000\n",
    "    )\n",
    "    \n",
    "    # Примерные входные данные\n",
    "    src = torch.randn(B, T_hist, feature_size)  # История после TradingProcessor\n",
    "    tgt = torch.randn(B, T_pred, output_size)   # Целевые значения\n",
    "    \n",
    "    # # Обучение (с учителем)\n",
    "    # model.train()\n",
    "    # output_train = model(src, tgt)\n",
    "    # print(f\"Выход при обучении (с учителем): {output_train.shape}\") # [B, 32, 1]\n",
    "    \n",
    "    # Инференс\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_infer = model(src)\n",
    "        print(f\"Выход при инференсе (авторегрессивно): {output_infer.shape}\") # [B, 32, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e97ccbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8481db42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f24bb83",
   "metadata": {},
   "source": [
    "### Тестированиe TradingModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d21bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "TradingTransformer(\n",
      "  (src_embedding): Linear(in_features=128, out_features=512, bias=True)\n",
      "  (tgt_embedding): Linear(in_features=1, out_features=512, bias=True)\n",
      "  (positional_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (src_layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (tgt_layer_norm): LayerNorm((1,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x EncoderBlock(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ffn): PositionwiseFeedForward(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-5): 6 x DecoderBlock(\n",
      "        (self_attn): MultiHeadAttention(\n",
      "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (cross_attn): MultiHeadAttention(\n",
      "          (W_q): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_k): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_v): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (W_o): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ffn): PositionwiseFeedForward(\n",
      "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (relu): ReLU()\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (output_projection): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.model_wrapper import TradingModel\n",
    "\n",
    "# model = TradingModel.from_config('src/lstm/lstm.json', device='mps')\n",
    "# model = TradingModel.from_config('src/tcn/tcn.json', device='mps')\n",
    "# model = TradingModel.from_config('src/cnn/cnn.json', device='mps')\n",
    "model = TradingModel.from_config('src/transformer/transformer.json', device='mps')\n",
    "print(model.device)\n",
    "print(model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c996e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be8265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
