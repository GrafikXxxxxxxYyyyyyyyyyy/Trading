{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2951421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход модели: torch.Size([4, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "# src/transformer/transformer.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Позиционные эмбеддинги для захвата временной информации.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [batch_size, seq_len, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Многоголовое внимание с маскированием для декодера.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "            \n",
    "        attn_probs = F.softmax(attn_scores, dim=-1)\n",
    "        attn_probs = self.dropout(attn_probs)\n",
    "        \n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        \n",
    "        # Применяем линейные преобразования и разделяем на головы\n",
    "        Q = self.W_q(query).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(key).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(value).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        # Применяем внимание\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Объединяем головы\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(\n",
    "            batch_size, -1, self.num_heads * self.d_k)\n",
    "        \n",
    "        # Финальное линейное преобразование\n",
    "        output = self.W_o(attn_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"\"\"\n",
    "    Позиционно-независимая полносвязная сеть.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, hidden_dim, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Слой энкодера трансформера.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, ff_hidden_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, ff_hidden_dim, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, src_mask=None):\n",
    "        # Самовнимание\n",
    "        attn_output = self.self_attn(x, x, x, src_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Полносвязная сеть\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Слой декодера трансформера.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_heads, ff_hidden_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads, dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, ff_hidden_dim, dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        # Самовнимание с маской\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Перекрёстное внимание\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Полносвязная сеть\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Энкодер трансформера.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, ff_hidden_dim, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_hidden_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Декодер трансформера.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, d_model, num_heads, ff_hidden_dim, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_hidden_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask=None, tgt_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_output, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "\n",
    "class TradingTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Мощная архитектура Transformer для прогнозирования цен на фондовом рынке.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size=256,\n",
    "        d_model=512,\n",
    "        num_heads=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        ff_hidden_dim=2048,\n",
    "        target_len=32,\n",
    "        dropout=0.1,\n",
    "        use_positional_encoding=True\n",
    "    ):\n",
    "        super(TradingTransformer, self).__init__()\n",
    "        self.feature_size = feature_size\n",
    "        self.d_model = d_model\n",
    "        self.target_len = target_len\n",
    "        self.use_positional_encoding = use_positional_encoding\n",
    "        \n",
    "        # Входная проекция\n",
    "        self.input_projection = nn.Linear(feature_size, d_model)\n",
    "        \n",
    "        # Позиционное кодирование\n",
    "        if use_positional_encoding:\n",
    "            self.pos_encoding = PositionalEncoding(d_model, dropout=dropout)\n",
    "        \n",
    "        # Энкодер и декодер\n",
    "        self.encoder = Encoder(\n",
    "            num_encoder_layers, d_model, num_heads, ff_hidden_dim, dropout\n",
    "        )\n",
    "        self.decoder = Decoder(\n",
    "            num_decoder_layers, d_model, num_heads, ff_hidden_dim, dropout\n",
    "        )\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.output_projection = nn.Linear(d_model, 1)\n",
    "        \n",
    "        # Маска для декодера (предотвращает заглядывание в будущее)\n",
    "        self.register_buffer(\n",
    "            'tgt_mask', \n",
    "            torch.tril(torch.ones(target_len, target_len)).bool()\n",
    "        )\n",
    "        \n",
    "        # Инициализация весов\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Инициализация весов.\"\"\"\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "                \n",
    "    def generate_square_subsequent_mask(self, sz):\n",
    "        \"\"\"Генерирует маску для предотвращения заглядывания в будущее.\"\"\"\n",
    "        mask = torch.tril(torch.ones(sz, sz)).bool()\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "        \n",
    "        Args:\n",
    "            src (torch.Tensor): Исторические данные [B, T_hist, F_hist=256].\n",
    "            tgt (torch.Tensor, optional): Целевые значения [B, T_pred, 1].\n",
    "            \n",
    "        Returns:\n",
    "            torch.Tensor: Прогнозы [B, T_pred, 1].\n",
    "        \"\"\"\n",
    "        batch_size = src.size(0)\n",
    "        \n",
    "        # Входная проекция\n",
    "        src_emb = self.input_projection(src)  # [B, T_hist, d_model]\n",
    "        \n",
    "        # Позиционное кодирование\n",
    "        if self.use_positional_encoding:\n",
    "            src_emb = self.pos_encoding(src_emb)\n",
    "            \n",
    "        # Маска для энкодера (обычно None для задач прогнозирования)\n",
    "        src_mask = None\n",
    "        \n",
    "        # Проход через энкодер\n",
    "        enc_output = self.encoder(src_emb, src_mask)  # [B, T_hist, d_model]\n",
    "        \n",
    "        # Для обучения используем teacher forcing\n",
    "        if self.training and tgt is not None:\n",
    "            # Подготавливаем декодер вход (сдвигаем tgt вправо и добавляем начальный токен)\n",
    "            # tgt: [B, T_pred, 1]\n",
    "            tgt_input = torch.zeros(batch_size, self.target_len, self.d_model, device=src.device)\n",
    "            # Простая реализация: используем нули как начальное состояние\n",
    "            # В более сложной версии можно использовать предыдущие прогнозы\n",
    "            \n",
    "            # Позиционное кодирование для декодера\n",
    "            if self.use_positional_encoding:\n",
    "                tgt_input = self.pos_encoding(tgt_input)\n",
    "                \n",
    "            # Маска для декодера\n",
    "            tgt_mask = self.generate_square_subsequent_mask(self.target_len).to(src.device)\n",
    "            \n",
    "            # Проход через декодер\n",
    "            dec_output = self.decoder(tgt_input, enc_output, src_mask, tgt_mask)\n",
    "            \n",
    "            # Выходная проекция\n",
    "            output = self.output_projection(dec_output)  # [B, T_pred, 1]\n",
    "            \n",
    "        else:\n",
    "            # Инференс: генерируем по одному шагу\n",
    "            outputs = []\n",
    "            # Начальное состояние\n",
    "            dec_input = torch.zeros(batch_size, 1, self.d_model, device=src.device)\n",
    "            \n",
    "            for i in range(self.target_len):\n",
    "                # Позиционное кодирование\n",
    "                if self.use_positional_encoding:\n",
    "                    dec_input = self.pos_encoding(dec_input)\n",
    "                    \n",
    "                # Маска для декодера\n",
    "                tgt_mask = self.generate_square_subsequent_mask(i + 1).to(src.device)\n",
    "                \n",
    "                # Проход через декодер\n",
    "                dec_output = self.decoder(\n",
    "                    dec_input, enc_output, src_mask, tgt_mask\n",
    "                )\n",
    "                \n",
    "                # Получаем прогноз для текущего шага\n",
    "                step_output = self.output_projection(dec_output[:, -1:, :])  # [B, 1, 1]\n",
    "                outputs.append(step_output)\n",
    "                \n",
    "                # Подготавливаем вход для следующего шага\n",
    "                # В реальной реализации можно использовать более сложную стратегию\n",
    "                next_input = torch.zeros(batch_size, 1, self.d_model, device=src.device)\n",
    "                dec_input = torch.cat([dec_input, next_input], dim=1)\n",
    "                \n",
    "            output = torch.cat(outputs, dim=1)  # [B, T_pred, 1]\n",
    "            \n",
    "        return output\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры модели\n",
    "    B, T_hist, feature_size = 4, 256, 256\n",
    "    T_pred = 32\n",
    "    output_size = 1\n",
    "    \n",
    "    # Создание модели\n",
    "    model = TradingTransformer(\n",
    "        feature_size=feature_size,\n",
    "        d_model=512,\n",
    "        num_heads=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_decoder_layers=6,\n",
    "        ff_hidden_dim=2048,\n",
    "        target_len=T_pred,\n",
    "        dropout=0.1,\n",
    "        use_positional_encoding=True\n",
    "    )\n",
    "    \n",
    "    # Примерные входные данные\n",
    "    src = torch.randn(B, T_hist, feature_size)  # История после TradingProcessor\n",
    "    tgt = torch.randn(B, T_pred, output_size)   # Целевые значения (опционально)\n",
    "    \n",
    "    # Прогон модели\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(src, tgt)\n",
    "        print(f\"Выход модели: {output.shape}\")  # [B, 32, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e33dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
