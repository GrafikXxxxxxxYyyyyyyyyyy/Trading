{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2951421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Выход при обучении: torch.Size([4, 32, 1])\n",
      "Выход при инференсе: torch.Size([4, 32, 1])\n"
     ]
    }
   ],
   "source": [
    "# src/lstm_new/lstm_new.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Улучшенный механизм внимания с маскировкой и масштабированием.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, attention_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attention_size = attention_size\n",
    "        \n",
    "        # Слои для вычисления внимания\n",
    "        self.W_enc = nn.Linear(hidden_size, attention_size, bias=False)\n",
    "        self.W_dec = nn.Linear(hidden_size, attention_size, bias=False)\n",
    "        self.V = nn.Linear(attention_size, 1, bias=False)\n",
    "        \n",
    "        # Маскировка для предотвращения утечки будущего\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, encoder_outputs, decoder_hidden, mask=None):\n",
    "        \"\"\"\n",
    "        Вычисляет контекстный вектор с помощью механизма внимания.\n",
    "        \n",
    "        Args:\n",
    "            encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "            decoder_hidden: [batch_size, hidden_size]\n",
    "            mask: [batch_size, seq_len] - маска для игнорирования padding\n",
    "            \n",
    "        Returns:\n",
    "            context_vector: [batch_size, hidden_size]\n",
    "            attention_weights: [batch_size, seq_len]\n",
    "        \"\"\"\n",
    "        # decoder_hidden: [batch_size, hidden_size] -> [batch_size, 1, hidden_size]\n",
    "        decoder_hidden_expanded = decoder_hidden.unsqueeze(1)\n",
    "        \n",
    "        # Вычисляем оценку внимания\n",
    "        energy = torch.tanh(\n",
    "            self.W_enc(encoder_outputs) + self.W_dec(decoder_hidden_expanded)\n",
    "        )\n",
    "        attention_scores = self.V(energy).squeeze(2)  # [batch_size, seq_len]\n",
    "        \n",
    "        # Применяем маску если есть\n",
    "        if mask is not None:\n",
    "            attention_scores.masked_fill_(mask == 0, -1e9)\n",
    "        \n",
    "        # Применяем softmax для получения весов внимания\n",
    "        attention_weights = F.softmax(attention_scores, dim=1)  # [batch_size, seq_len]\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # Вычисляем контекстный вектор\n",
    "        context_vector = torch.bmm(attention_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        \n",
    "        return context_vector, attention_weights\n",
    "\n",
    "\n",
    "class LSTMEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Улучшенный LSTM энкодер с двунаправленными слоями и dropout.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super(LSTMEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Двунаправленный LSTM для лучшего захвата контекста\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Проекция для согласования размерностей\n",
    "        self.projection = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: [batch_size, seq_len, input_size]\n",
    "            \n",
    "        Returns:\n",
    "            outputs: [batch_size, seq_len, hidden_size]\n",
    "            (h_n, c_n): кортеж скрытых состояний\n",
    "        \"\"\"\n",
    "        outputs, (h_n, c_n) = self.lstm(x)\n",
    "        # Проекция для уменьшения размерности от двунаправленного LSTM\n",
    "        outputs = self.projection(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        return outputs, (h_n, c_n)\n",
    "\n",
    "\n",
    "class LSTMDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Улучшенный LSTM декодер с механизмом внимания и teacher forcing.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size, attention, dropout=0.2):\n",
    "        super(LSTMDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.attention = attention\n",
    "        \n",
    "        # LSTM декодер\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size + hidden_size,  # вход + контекст\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.output_projection = nn.Sequential(\n",
    "            nn.Linear(hidden_size + hidden_size, hidden_size),  # hidden + context\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "        \n",
    "    def forward(self, encoder_outputs, encoder_hidden, targets=None, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder_outputs: [batch_size, seq_len, hidden_size]\n",
    "            encoder_hidden: кортеж (h_n, c_n) из энкодера\n",
    "            targets: [batch_size, target_len, output_size] - целевые значения\n",
    "            teacher_forcing_ratio: вероятность использования teacher forcing\n",
    "            \n",
    "        Returns:\n",
    "            outputs: [batch_size, target_len, output_size]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = encoder_outputs.size()\n",
    "        target_len = 32  # фиксированная длина прогноза\n",
    "        \n",
    "        # Инициализация выходов\n",
    "        outputs = torch.zeros(batch_size, target_len, self.output_size, device=encoder_outputs.device)\n",
    "        \n",
    "        # Инициализация скрытого состояния декодера\n",
    "        # Берем последние слои из энкодера\n",
    "        h_n, c_n = encoder_hidden\n",
    "        decoder_hidden = h_n[-2:].contiguous()  # последние 2 слоя\n",
    "        decoder_cell = c_n[-2:].contiguous()\n",
    "        \n",
    "        # Начальное входное значение (последнее значение из истории)\n",
    "        decoder_input = encoder_outputs[:, -1:, :1]  # берем только цену закрытия\n",
    "        \n",
    "        for t in range(target_len):\n",
    "            # Вычисляем контекст через внимание\n",
    "            context_vector, _ = self.attention(\n",
    "                encoder_outputs, \n",
    "                decoder_hidden[-1]  # последний слой скрытого состояния\n",
    "            )\n",
    "            \n",
    "            # Подготавливаем вход для LSTM\n",
    "            lstm_input = torch.cat([decoder_input, context_vector.unsqueeze(1)], dim=2)\n",
    "            \n",
    "            # Пропускаем через LSTM\n",
    "            lstm_output, (decoder_hidden, decoder_cell) = self.lstm(\n",
    "                lstm_input, \n",
    "                (decoder_hidden, decoder_cell)\n",
    "            )\n",
    "            \n",
    "            # Подготавливаем вход для выходного слоя\n",
    "            output_input = torch.cat([lstm_output.squeeze(1), context_vector], dim=1)\n",
    "            \n",
    "            # Вычисляем выход\n",
    "            output = self.output_projection(output_input)\n",
    "            outputs[:, t:t+1] = output.unsqueeze(1)\n",
    "            \n",
    "            # Подготовка decoder_input для следующего шага\n",
    "            use_teacher_forcing = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            if use_teacher_forcing and targets is not None and t < targets.size(1):\n",
    "                decoder_input = targets[:, t:t+1]  # использовать реальное значение\n",
    "            else:\n",
    "                decoder_input = output.unsqueeze(1)  # использовать предсказание\n",
    "                \n",
    "        return outputs\n",
    "\n",
    "\n",
    "class TradingLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Мощная LSTM Encoder-Decoder модель с улучшенным вниманием для прогнозирования цен.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_size=256,\n",
    "        encoder_hidden_size=512,\n",
    "        decoder_hidden_size=512,\n",
    "        num_layers=2,\n",
    "        output_size=1,\n",
    "        target_len=32,\n",
    "        dropout=0.3,\n",
    "        teacher_forcing_ratio=0.5\n",
    "    ):\n",
    "        super(TradingLSTM, self).__init__()\n",
    "        self.target_len = target_len\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "        \n",
    "        # Механизм внимания\n",
    "        self.attention = Attention(encoder_hidden_size, encoder_hidden_size // 2)\n",
    "        \n",
    "        # Энкодер\n",
    "        self.encoder = LSTMEncoder(\n",
    "            input_size=feature_size,\n",
    "            hidden_size=encoder_hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Декодер\n",
    "        self.decoder = LSTMDecoder(\n",
    "            input_size=output_size,  # прогнозируем только цену закрытия\n",
    "            hidden_size=decoder_hidden_size,\n",
    "            output_size=output_size,\n",
    "            attention=self.attention,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Нормализация входа\n",
    "        self.layer_norm = nn.LayerNorm(feature_size)\n",
    "        \n",
    "    def forward(self, src, tgt=None):\n",
    "        \"\"\"\n",
    "        Прямой проход модели.\n",
    "        \n",
    "        Args:\n",
    "            src: [batch_size, seq_len, feature_size] - исторические данные\n",
    "            tgt: [batch_size, target_len, output_size] - целевые значения (для обучения)\n",
    "            \n",
    "        Returns:\n",
    "            outputs: [batch_size, target_len, output_size] - прогнозы\n",
    "        \"\"\"\n",
    "        # Нормализация входа\n",
    "        src = self.layer_norm(src)\n",
    "        \n",
    "        # Энкодер\n",
    "        encoder_outputs, encoder_hidden = self.encoder(src)\n",
    "        \n",
    "        # Декодер\n",
    "        outputs = self.decoder(\n",
    "            encoder_outputs, \n",
    "            encoder_hidden, \n",
    "            targets=tgt,\n",
    "            teacher_forcing_ratio=self.teacher_forcing_ratio if self.training else 0.0\n",
    "        )\n",
    "        \n",
    "        return outputs\n",
    "\n",
    "\n",
    "# Пример использования\n",
    "if __name__ == \"__main__\":\n",
    "    # Параметры\n",
    "    batch_size, seq_len, feature_size = 4, 256, 256\n",
    "    target_len, output_size = 32, 1\n",
    "    \n",
    "    # Создание модели\n",
    "    model = TradingLSTM(\n",
    "        feature_size=feature_size,\n",
    "        encoder_hidden_size=512,\n",
    "        decoder_hidden_size=512,\n",
    "        num_layers=2,\n",
    "        output_size=output_size,\n",
    "        target_len=target_len,\n",
    "        dropout=0.3,\n",
    "        teacher_forcing_ratio=0.5\n",
    "    )\n",
    "    \n",
    "    # Тестовые данные\n",
    "    src = torch.randn(batch_size, seq_len, feature_size)\n",
    "    tgt = torch.randn(batch_size, target_len, output_size)\n",
    "    \n",
    "    # Обучение\n",
    "    model.train()\n",
    "    output_train = model(src, tgt)\n",
    "    print(f\"Выход при обучении: {output_train.shape}\")  # [4, 32, 1]\n",
    "    \n",
    "    # Инференс\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output_infer = model(src)\n",
    "        print(f\"Выход при инференсе: {output_infer.shape}\")  # [4, 32, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
